{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa221501-f6d9-4e90-bde0-824677f328d7",
   "metadata": {},
   "source": [
    "# Question Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e31dd21-9586-4a95-bf6e-3cb973e8a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import spacy\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75a9cb67-c385-428e-a81f-bbf8bba6f9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/markusmuller/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28300f1b-fb8e-4533-95da-03b3c8a3dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with relevant categories\n",
    "cat_target_names = [\n",
    "    'HUM',  # human beings\n",
    "    'LOC',  # locations\n",
    "    'NUM',  # numeric values\n",
    "    'ENTY', # entities\n",
    "]\n",
    "\n",
    "cat_map_dict = {\n",
    "    'HUM': 0,\n",
    "    'LOC': 1,\n",
    "    'NUM': 2,\n",
    "    'ENTY': 3\n",
    "}\n",
    "\n",
    "sub_target_names = [\n",
    "    'HUM:ind',     # an individual\n",
    "    'HUM:gr',      # a group or organization of persons\n",
    "    'LOC:other',   # other location\n",
    "    'LOC:country', # countries\n",
    "    'LOC:city',    # cities\n",
    "    'NUM:count',   # number of somthing\n",
    "    'NUM:date',    # dates\n",
    "    'ENTY:other',  # other entities\n",
    "    'ENTY:cremat', # ?\n",
    "    'ENTY:animal', # animals\n",
    "    'ENTY:food'    # food\n",
    "]\n",
    "\n",
    "sub_cat_map_dict = {\n",
    "    'HUM:ind': 0,\n",
    "    'HUM:gr': 1,\n",
    "    'LOC:other': 2,\n",
    "    'LOC:country': 3,\n",
    "    'LOC:city': 4, \n",
    "    'NUM:count': 5,\n",
    "    'NUM:date': 6,\n",
    "    'ENTY:other': 7,\n",
    "    'ENTY:cremat': 8,\n",
    "    'ENTY:animal': 9,\n",
    "    'ENTY:food': 10 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d21da3-2065-481c-b3fd-bcf4ae0eabe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "DATA_PATH_WEB_TRAIN = \"Data/question_clf_train_set.txt\"\n",
    "DATA_PATH_WEB_TEST = \"Data/question_clf_test_set.txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02910380-90a2-4d9a-9fc4-1b040636a3f5",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06004425-a1a4-4ff6-89c3-156f2c2356d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_web_data(data_path):\n",
    "    # read file and add question with cat to list\n",
    "    question_cat_list = []\n",
    "    question_list = []\n",
    "\n",
    "    with open(data_path, 'r', encoding = \"ISO-8859-1\") as f:\n",
    "        for line in f:\n",
    "            q_cat, q = line.split(\" \", 1)\n",
    "            # check if question \n",
    "            if q_cat.split(\":\")[0] in cat_target_names:\n",
    "                question_cat_list.append(q_cat)\n",
    "                question_list.append(q.strip())\n",
    "\n",
    "    assert(len(question_cat_list) == len(question_list))\n",
    "\n",
    "    # create Dataframe\n",
    "    df = pd.DataFrame({\"sub_cat\": question_cat_list, \"question\": question_list})\n",
    "\n",
    "    # split sub_cat to get just the category\n",
    "    df[\"cat\"] = df[\"sub_cat\"].str.split(\":\", n=1, expand=True)[0]\n",
    "\n",
    "    # encode category with values\n",
    "    df[\"cat_encoded\"] = df[\"cat\"].replace(cat_map_dict)\n",
    "\n",
    "    # encode sub category with values\n",
    "    df[\"sub_cat_encoded\"] = df[\"sub_cat\"].replace(sub_cat_map_dict)\n",
    "\n",
    "    # replace string in sub_cat_encoded\n",
    "    df[\"sub_cat_encoded\"] =  df['sub_cat_encoded'].apply(lambda x: 99 if str(type(x))==\"<class 'str'>\" else x)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "029deb9b-070c-42d8-a352-d3a539fb70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_web_train = process_web_data(DATA_PATH_WEB_TRAIN)\n",
    "df_data_web_test = process_web_data(DATA_PATH_WEB_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cae31c64-b847-415c-8ac2-595d17124c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_cat</th>\n",
       "      <th>question</th>\n",
       "      <th>cat</th>\n",
       "      <th>cat_encoded</th>\n",
       "      <th>sub_cat_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTY:cremat</td>\n",
       "      <td>What films featured the character Popeye Doyle ?</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTY:animal</td>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HUM:ind</td>\n",
       "      <td>What contemptible scoundrel stole the cork fro...</td>\n",
       "      <td>HUM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HUM:gr</td>\n",
       "      <td>What team did baseball 's St. Louis Browns bec...</td>\n",
       "      <td>HUM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HUM:title</td>\n",
       "      <td>What is the oldest profession ?</td>\n",
       "      <td>HUM</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>ENTY:other</td>\n",
       "      <td>What 's the shape of a camel 's spine ?</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>ENTY:currency</td>\n",
       "      <td>What type of currency is used in China ?</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>NUM:temp</td>\n",
       "      <td>What is the temperature today ?</td>\n",
       "      <td>NUM</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>NUM:temp</td>\n",
       "      <td>What is the temperature for cooking ?</td>\n",
       "      <td>NUM</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>ENTY:currency</td>\n",
       "      <td>What currency is used in Australia ?</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4204 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sub_cat                                           question   cat  \\\n",
       "0       ENTY:cremat   What films featured the character Popeye Doyle ?  ENTY   \n",
       "1       ENTY:animal  What fowl grabs the spotlight after the Chines...  ENTY   \n",
       "2           HUM:ind  What contemptible scoundrel stole the cork fro...   HUM   \n",
       "3            HUM:gr  What team did baseball 's St. Louis Browns bec...   HUM   \n",
       "4         HUM:title                    What is the oldest profession ?   HUM   \n",
       "...             ...                                                ...   ...   \n",
       "4199     ENTY:other            What 's the shape of a camel 's spine ?  ENTY   \n",
       "4200  ENTY:currency           What type of currency is used in China ?  ENTY   \n",
       "4201       NUM:temp                    What is the temperature today ?   NUM   \n",
       "4202       NUM:temp              What is the temperature for cooking ?   NUM   \n",
       "4203  ENTY:currency               What currency is used in Australia ?  ENTY   \n",
       "\n",
       "      cat_encoded  sub_cat_encoded  \n",
       "0               3                8  \n",
       "1               3                9  \n",
       "2               0                0  \n",
       "3               0                1  \n",
       "4               0               99  \n",
       "...           ...              ...  \n",
       "4199            3                7  \n",
       "4200            3               99  \n",
       "4201            2               99  \n",
       "4202            2               99  \n",
       "4203            3               99  \n",
       "\n",
       "[4204 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_web_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91127955-08d3-4e33-8b34-fc71fb7cf042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data_web_train[df_data_web_train[\"sub_cat_encoded\"] != 99]\n",
    "df_test = df_data_web_test[df_data_web_test[\"sub_cat_encoded\"] != 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e824b06c-2e6c-4575-83ea-b9886903f733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3119 entries, 0 to 4199\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   sub_cat          3119 non-null   object\n",
      " 1   question         3119 non-null   object\n",
      " 2   cat              3119 non-null   object\n",
      " 3   cat_encoded      3119 non-null   int64 \n",
      " 4   sub_cat_encoded  3119 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 146.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcdf8ddc-27a9-4092-ab05-dd038838c1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 220 entries, 1 to 351\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   sub_cat          220 non-null    object\n",
      " 1   question         220 non-null    object\n",
      " 2   cat              220 non-null    object\n",
      " 3   cat_encoded      220 non-null    int64 \n",
      " 4   sub_cat_encoded  220 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 10.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97deb850-92d3-428c-a4b3-83d81fa7c2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HUM     1151\n",
       "LOC      748\n",
       "ENTY     639\n",
       "NUM      581\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96cd0620-dada-4242-939c-857ea2742cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOC     71\n",
       "HUM     61\n",
       "NUM     56\n",
       "ENTY    32\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab661342-754b-4b0b-a0a3-c25be2f5c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_train, df_test]\n",
    "df_all = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f021906-2723-4847-b77f-1d1e1221c2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HUM     0.362983\n",
       "LOC     0.245283\n",
       "ENTY    0.200958\n",
       "NUM     0.190776\n",
       "Name: cat, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"cat\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb9298-2665-4375-a73e-576ce9100f29",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "daa88a3d-e16b-4a0a-a407-851501e32ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple preprocessing\n",
    "# just calculating bag of words\n",
    "def simple_pre(df):\n",
    "    question_list = df[\"question\"].values\n",
    "    y = df[\"sub_cat_encoded\"].values\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    bow_vec = vectorizer.fit_transform(question_list)\n",
    "    \n",
    "    return bow_vec, y\n",
    "\n",
    "# removeing stopwords and numbers\n",
    "def remove_stopwords_pre(df):\n",
    "    question_list = df[\"question\"].values\n",
    "    question_list_pre = []\n",
    "    for q in question_list:\n",
    "        question_tokenized = tokenizer.tokenize(q)\n",
    "        question_stopwords_removed = [w for w in question_tokenized if not w.lower() in stop_words]\n",
    "        str_join = ' '.join(question_stopwords_removed)\n",
    "        question_list_pre.append(str_join)\n",
    "    \n",
    "    y = df[\"sub_cat_encoded\"].values\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    bow_vec = vectorizer.fit_transform(question_list_pre)\n",
    "    \n",
    "    return bow_vec, y\n",
    "\n",
    "# add Names Entities\n",
    "def add_ner_pre(df):\n",
    "    # list with NER labels from spacy\n",
    "    ner_list = nlp.pipe_labels['ner']\n",
    "    question_list = df[\"question\"].values\n",
    "    \n",
    "    question_NER = {}\n",
    "    for idx, q in enumerate(question_list):\n",
    "        q = nlp(q)\n",
    "        ent_list = []\n",
    "        for ent in q.ents:\n",
    "            ent_list.append(ent.label_)\n",
    "        question_NER[idx] = ent_list\n",
    "    \n",
    "    rows = len(question_list)\n",
    "    cols = len(ner_list)\n",
    "    ner_encoded = np.zeros(shape=(rows, cols))\n",
    "    \n",
    "    for key, value in question_NER.items():\n",
    "        for ent in value:\n",
    "            update_at_idx = ner_list.index(ent)\n",
    "            ner_encoded[key][update_at_idx] = 1\n",
    "        \n",
    "    vectorizer = CountVectorizer()\n",
    "    bow_vec = vectorizer.fit_transform(question_list)\n",
    "    \n",
    "    # combine bow_vec with ner_encoded\n",
    "    X = hstack((bow_vec, ner_encoded))    \n",
    "    X = X.toarray()\n",
    "    y = df[\"sub_cat_encoded\"].values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f4911f3-92fe-4086-a622-4a5c362f6628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement KFold cross validation \n",
    "def valdiate_kfold(df, preprocess_function):\n",
    "    # define F\n",
    "    X, y = preprocess_function(df)\n",
    "    lsvc = LinearSVC()\n",
    "    n_splits = 5\n",
    "    kfold = KFold(n_splits=n_splits)\n",
    "\n",
    "    accurarcy_list = []\n",
    "    idx = 0\n",
    "    # when using KFold remove y\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        idx += 1    \n",
    "        # split the data into training and test sets\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # fit the model with the data\n",
    "        lsvc.fit(X_train, y_train)\n",
    "        y_pred = lsvc.predict(X_test)\n",
    "        # calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accurarcy_list.append(accuracy)\n",
    "        print(f\"Accuracy fold {idx}: {accuracy}\")\n",
    "        \n",
    "    print(f\"mean accuracy: {np.mean(accurarcy_list)}, std: {np.std(accurarcy_list)}\")\n",
    "\n",
    "# Funktion to implement stratified KFold cross validation \n",
    "# for imbalanced dataset\n",
    "def valdiate_skf(df, preprocess_function):\n",
    "    X, y = preprocess_function(df)\n",
    "    lsvc = LinearSVC()\n",
    "    n_splits = 5\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "    accurarcy_list = []\n",
    "    idx = 0\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        idx += 1    \n",
    "        # split the data into training and test sets\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # fit the model with the data\n",
    "        lsvc.fit(X_train, y_train)\n",
    "        y_pred = lsvc.predict(X_test)\n",
    "        # calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accurarcy_list.append(accuracy)\n",
    "        print(f\"Accuracy fold {idx}: {accuracy}\")\n",
    "\n",
    "    print(f\"mean accuracy: {np.mean(accurarcy_list)}, std: {np.std(accurarcy_list)}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7010f9-3ae9-4eb5-8dd3-7bbbbb8bc886",
   "metadata": {},
   "source": [
    "## Train Classifier\n",
    "- since the main categories are slightly imbalanced I will use stratifed KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed7dd0dd-4a30-421e-9bd6-6c5ea4cfe85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.8547904191616766\n",
      "Accuracy fold 2: 0.8143712574850299\n",
      "Accuracy fold 3: 0.8488023952095808\n",
      "Accuracy fold 4: 0.842814371257485\n",
      "Accuracy fold 5: 0.8440779610194903\n",
      "mean accuracy: 0.8409712808266525, std: 0.01394922666482055\n"
     ]
    }
   ],
   "source": [
    "# simple preprocessing\n",
    "valdiate_skf(df_all, simple_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3b7a36b-08f3-4e3f-9b89-f2a1dfa087e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.7544910179640718\n",
      "Accuracy fold 2: 0.7200598802395209\n",
      "Accuracy fold 3: 0.7170658682634731\n",
      "Accuracy fold 4: 0.75\n",
      "Accuracy fold 5: 0.7436281859070465\n",
      "mean accuracy: 0.7370489904748224, std: 0.015512535724976228\n"
     ]
    }
   ],
   "source": [
    "# with stopword and number removal\n",
    "valdiate_skf(df_all, remove_stopwords_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7ba1ca3-5ba4-43eb-9add-9c718f0f48b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.8562874251497006\n",
      "Accuracy fold 2: 0.8143712574850299\n",
      "Accuracy fold 3: 0.8547904191616766\n",
      "Accuracy fold 4: 0.8368263473053892\n",
      "Accuracy fold 5: 0.8530734632683659\n",
      "mean accuracy: 0.8430697824740324, std: 0.015967083960133507\n"
     ]
    }
   ],
   "source": [
    "# with NER added\n",
    "valdiate_skf(df_all, add_ner_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b4eb21-5cc0-4033-9e70-69470c906813",
   "metadata": {},
   "source": [
    "# Train Sub-Category classifier\n",
    "\n",
    "- Question -> Category [HUM, NUM, LOC, ENTY]\n",
    "-> [HUM]\n",
    "    - clf_HUM -> [ind, gr]\n",
    "- ...\n",
    "- we have 4 classifier for in category classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e88efd1-c2c4-40e7-8a97-bacf93a1e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hum = df_all[df_all[\"cat_encoded\"] == 0]\n",
    "df_loc = df_all[df_all[\"cat_encoded\"] == 1]\n",
    "df_num = df_all[df_all[\"cat_encoded\"] == 2]\n",
    "df_enty = df_all[df_all[\"cat_encoded\"] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d96c5f90-6b6d-491d-8086-78ef7b83b7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HUM:ind    1017\n",
       "HUM:gr      195\n",
       "Name: sub_cat, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hum[\"sub_cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "686a538a-f5a7-4aee-96c5-e71aea3df532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOC:other      514\n",
       "LOC:country    158\n",
       "LOC:city       147\n",
       "Name: sub_cat, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loc[\"sub_cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5878ef94-8e57-41b1-a1de-f24dd7cd5afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUM:count    372\n",
       "NUM:date     265\n",
       "Name: sub_cat, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num[\"sub_cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e05d80a3-3ddf-438a-b682-cc93101b941e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENTY:other     229\n",
       "ENTY:cremat    207\n",
       "ENTY:animal    128\n",
       "ENTY:food      107\n",
       "Name: sub_cat, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enty[\"sub_cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9876abd-00fa-4c0b-85b3-f639381cd427",
   "metadata": {},
   "source": [
    "## Train and Validate Sub-Category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275a6f4-4088-486f-88c8-e87b5d05ee75",
   "metadata": {},
   "source": [
    "### HUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b67c27df-3061-45fa-8e50-45596805ea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.9300411522633745\n",
      "Accuracy fold 2: 0.9218106995884774\n",
      "Accuracy fold 3: 0.9504132231404959\n",
      "Accuracy fold 4: 0.9504132231404959\n",
      "Accuracy fold 5: 0.9297520661157025\n",
      "mean accuracy: 0.9364860728497092, std: 0.011748884703312121\n"
     ]
    }
   ],
   "source": [
    "# skf for hum\n",
    "# simple preprocessing\n",
    "valdiate_skf(df_hum, simple_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d09514a-463a-424e-a70f-a3dfcdf7929d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.8847736625514403\n",
      "Accuracy fold 2: 0.9176954732510288\n",
      "Accuracy fold 3: 0.9586776859504132\n",
      "Accuracy fold 4: 0.9297520661157025\n",
      "Accuracy fold 5: 0.9256198347107438\n",
      "mean accuracy: 0.9233037445158658, std: 0.023724589693505202\n"
     ]
    }
   ],
   "source": [
    "# stopword preprocessing\n",
    "valdiate_skf(df_hum, remove_stopwords_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "46353e59-a0cd-4eb6-8e2e-f969965355fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.9300411522633745\n",
      "Accuracy fold 2: 0.9176954732510288\n",
      "Accuracy fold 3: 0.9545454545454546\n",
      "Accuracy fold 4: 0.9504132231404959\n",
      "Accuracy fold 5: 0.9214876033057852\n",
      "mean accuracy: 0.9348365813012277, std: 0.015007200897664632\n"
     ]
    }
   ],
   "source": [
    "# NER preprocessing\n",
    "valdiate_skf(df_hum, add_ner_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59492bb3-19b6-4eb6-bb11-9688ffd9f9de",
   "metadata": {},
   "source": [
    "### LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bfe5200b-bdca-4a6f-a576-a94ea9847db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.9878048780487805\n",
      "Accuracy fold 2: 0.975609756097561\n",
      "Accuracy fold 3: 0.9512195121951219\n",
      "Accuracy fold 4: 0.975609756097561\n",
      "Accuracy fold 5: 0.9754601226993865\n",
      "mean accuracy: 0.9731408050276821, std: 0.01194277011628502\n"
     ]
    }
   ],
   "source": [
    "# skf for loc\n",
    "valdiate_skf(df_loc, simple_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "666843ea-4f84-4d2d-9b05-188fb316a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.9878048780487805\n",
      "Accuracy fold 2: 0.975609756097561\n",
      "Accuracy fold 3: 0.9634146341463414\n",
      "Accuracy fold 4: 0.9817073170731707\n",
      "Accuracy fold 5: 0.9754601226993865\n",
      "mean accuracy: 0.976799341613048, std: 0.008094060418876024\n"
     ]
    }
   ],
   "source": [
    "# stopword preprocessing\n",
    "valdiate_skf(df_loc, remove_stopwords_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1d73fcf5-e815-431b-91ea-65d2271f0121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.9878048780487805\n",
      "Accuracy fold 2: 0.9695121951219512\n",
      "Accuracy fold 3: 0.9573170731707317\n",
      "Accuracy fold 4: 0.975609756097561\n",
      "Accuracy fold 5: 0.9754601226993865\n",
      "mean accuracy: 0.9731408050276821, std: 0.00990017465648438\n"
     ]
    }
   ],
   "source": [
    "# NER preprocessing\n",
    "valdiate_skf(df_loc, add_ner_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823fdc25-d31b-4426-94f8-990cb59e3c67",
   "metadata": {},
   "source": [
    "### NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "91e00a6d-ffa5-4e7b-b994-d9cba689655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 1.0\n",
      "Accuracy fold 2: 0.9921875\n",
      "Accuracy fold 3: 0.984251968503937\n",
      "Accuracy fold 4: 1.0\n",
      "Accuracy fold 5: 1.0\n",
      "mean accuracy: 0.9952878937007874, std: 0.006293106122982452\n"
     ]
    }
   ],
   "source": [
    "# kfold for num\n",
    "valdiate_kfold(df_num, simple_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ff68ac8e-7122-49b9-9d44-ca536fb6e18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.9921875\n",
      "Accuracy fold 2: 1.0\n",
      "Accuracy fold 3: 0.984251968503937\n",
      "Accuracy fold 4: 0.9921259842519685\n",
      "Accuracy fold 5: 1.0\n",
      "mean accuracy: 0.9937130905511811, std: 0.0058891361703223965\n"
     ]
    }
   ],
   "source": [
    "# stopword preprocessing\n",
    "valdiate_kfold(df_num, remove_stopwords_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eeb32492-26ae-4a7a-aba8-5dfc6e46ae1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 1.0\n",
      "Accuracy fold 2: 1.0\n",
      "Accuracy fold 3: 0.984251968503937\n",
      "Accuracy fold 4: 1.0\n",
      "Accuracy fold 5: 1.0\n",
      "mean accuracy: 0.9968503937007874, std: 0.0062992125984251855\n"
     ]
    }
   ],
   "source": [
    "# NER preprocessing\n",
    "valdiate_kfold(df_num, add_ner_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e438d-77e2-4faf-aec4-bd92e30d510c",
   "metadata": {},
   "source": [
    "### ENTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "504a141a-89a6-4ca7-ac50-790d23460fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.7851851851851852\n",
      "Accuracy fold 2: 0.753731343283582\n",
      "Accuracy fold 3: 0.7985074626865671\n",
      "Accuracy fold 4: 0.7835820895522388\n",
      "Accuracy fold 5: 0.8432835820895522\n",
      "mean accuracy: 0.7928579325594252, std: 0.02915635651214357\n"
     ]
    }
   ],
   "source": [
    "# kfold for enty\n",
    "valdiate_kfold(df_enty, simple_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ef3a6667-c4b6-4e98-a729-248949e87663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.7777777777777778\n",
      "Accuracy fold 2: 0.7910447761194029\n",
      "Accuracy fold 3: 0.7761194029850746\n",
      "Accuracy fold 4: 0.8134328358208955\n",
      "Accuracy fold 5: 0.7985074626865671\n",
      "mean accuracy: 0.7913764510779437, std: 0.013821337668998094\n"
     ]
    }
   ],
   "source": [
    "# stopword preprocessing\n",
    "valdiate_kfold(df_enty, remove_stopwords_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "59258fc7-b83d-43cb-8680-2d997852f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fold 1: 0.7703703703703704\n",
      "Accuracy fold 2: 0.7686567164179104\n",
      "Accuracy fold 3: 0.7611940298507462\n",
      "Accuracy fold 4: 0.746268656716418\n",
      "Accuracy fold 5: 0.8134328358208955\n",
      "mean accuracy: 0.7719845218352681, std: 0.02240260226927894\n"
     ]
    }
   ],
   "source": [
    "# NER preprocessing\n",
    "valdiate_kfold(df_enty, add_ner_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1a2b9-1c3b-4a27-9ec0-717dfe17c28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
